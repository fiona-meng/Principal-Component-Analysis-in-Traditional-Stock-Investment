{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320eb7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from requests.exceptions import HTTPError\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from numpy.linalg import eig\n",
    "from scipy.linalg import svd\n",
    "from numpy import mean\n",
    "from numpy import cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305bf045",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3695e64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import mean, std\n",
    "from scipy.linalg import svd\n",
    "\n",
    "def pca(data):\n",
    "    # Define a matrix\n",
    "    A = np.array(data)\n",
    "    \n",
    "    # Calculate the mean of each column\n",
    "    M = mean(A.T, axis=1)\n",
    "    \n",
    "    # Calculate the standard deviation of each column\n",
    "    S = std(A.T, axis=1, ddof=1)\n",
    "    \n",
    "    # Standardize the data by subtracting column means and dividing by standard deviation\n",
    "    X = (A - M) / S\n",
    "    \n",
    "    # Calculate covariance matrix of standardized matrix\n",
    "    C = X.T.dot(X) * (1 / (X.shape[0] - 1))\n",
    "    \n",
    "    # Perform Singular Value Decomposition (SVD) on covariance matrix\n",
    "    V, s, V_T = svd(C, full_matrices=False)\n",
    "    \n",
    "    # Project data\n",
    "    pca = X.dot(V)\n",
    "    \n",
    "    # Calculate eigenvalues from the singular values\n",
    "    eigenvalues = s**2 / (X.shape[0] - 1)\n",
    "\n",
    "    # Calculate total variance\n",
    "    total_variance = np.sum(eigenvalues)\n",
    "\n",
    "    # Calculate explained variance ratio\n",
    "    explained_variance_ratio = eigenvalues / total_variance\n",
    "\n",
    "    return pca, explained_variance_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419b86ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the desired minimum and maximum values for the scaled data\n",
    "min_val = 0\n",
    "max_val = 1\n",
    "\n",
    "# Normalize data between 0 and 1\n",
    "def normalization(column):\n",
    "    col_std = (column - column.min()) / (column.max() - column.min())\n",
    "    col_scaled = col_std * (max_val - min_val) + min_val\n",
    "    return col_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a16d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract today's data\n",
    "# Define a list of stocks in technology sector\n",
    "stocks = ['AAPL', 'ABCL', 'ABNB', 'ADBE','AMD', \n",
    "          'APPS',  'ASML',  'AVGO','AZPN', 'BIDU', \n",
    "          'BR', 'CARR', 'CDNS', 'CHGG', 'CRM', 'CSCO', \n",
    "           'DLO', 'DOX', 'DXCM', 'ET', 'EXEL', 'EXPI', 'FLGT',\n",
    "           'FUTU', 'GBDC', 'GGG', 'GLOB',  'GNRC', 'GOOGL', 'GRMN', \n",
    "           'HAE', 'HLNE', 'IDXX',  'INTC', 'INTU', 'KIDS', \n",
    "          'LOGI', 'LPRO', 'LRCX', 'MCHP','MDRX', 'MDT', 'MEDP', 'MELI', \n",
    "            'MKTX', 'MRNA', 'MSFT', 'MU', 'NOW', 'NTES', 'NVDA', \n",
    "           'NXPI', 'OLED', 'OLLI', 'ON',  'PAYC', 'PCRX', \n",
    "           'PYPL', 'QCOM', 'SEDG', 'TSLA', 'TTD', 'TXN', 'ZM']\n",
    "\n",
    "\n",
    "# Create an empty list to store ratios data for each stock\n",
    "pe_ratios = []\n",
    "pes_ratios = []\n",
    "de_ratios = []\n",
    "pb_ratios = []\n",
    "pr_ratios = []\n",
    "\n",
    "# Loop through each stock in the list and retrieve its ratios from Yahoo Finance\n",
    "for stock in stocks:\n",
    "    ticker = yf.Ticker(stock)\n",
    "    pe_ratio = ticker.info['trailingPE']\n",
    "    pes_ratio = ticker.info['trailingEps']\n",
    "    de_ratio = ticker.info['debtToEquity']\n",
    "    pb_ratio = ticker.info['priceToBook']\n",
    "    pr_ratio = ticker.info['fiftyTwoWeekHigh'] - ticker.info['fiftyTwoWeekLow']\n",
    "    \n",
    "    pe_ratios.append(pe_ratio)\n",
    "    pes_ratios.append(pes_ratio)\n",
    "    de_ratios.append(de_ratio)\n",
    "    pb_ratios.append(pb_ratio)\n",
    "    pr_ratios.append(pr_ratio)\n",
    "    \n",
    "    \n",
    "# Write ratios data to a CSV file\n",
    "with open('technology_stock_5ratios.csv', mode='w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Stock', 'Price to Earnings', \"Earnings Per Share\", \n",
    "                     \"Dept to Equity\", 'Price to Book', 'Price to 52W Range'])\n",
    "    for i in range(len(stocks)):\n",
    "        writer.writerow([stocks[i], pe_ratios[i], pes_ratios[i], de_ratios[i], pb_ratios[i], pr_ratios[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedbe9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('technology_stock_5ratios.csv')\n",
    "df.set_index(\"Stock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e8b2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply normalization to all columns except the first one\n",
    "df.iloc[:, 1:] = df.iloc[:, 1:].apply(normalization)\n",
    "normalized_data = df\n",
    "\n",
    "# Add reference point\n",
    "new_row = pd.DataFrame([['REFERENCE POINT', 0, 1, 0, 0, 0]], columns=normalized_data.columns)\n",
    "\n",
    "# Add the new row using pandas.concat\n",
    "normalized_data = pd.concat([normalized_data, new_row], ignore_index=True)\n",
    "\n",
    "\n",
    "modified_data = normalized_data.copy()\n",
    "\n",
    "print(modified_data)\n",
    "# subtract normalize data from 1\n",
    "modified_data.iloc[:, [1, 3, 4, 5]] =1 - normalized_data.iloc[:, [1, 3, 4, 5]]\n",
    "\n",
    "modified_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d0b254",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# stock name\n",
    "stocks = modified_data.iloc[: , 0]\n",
    "# stock data\n",
    "data = modified_data.iloc[: , 1 :]\n",
    "# pca \n",
    "reducedData, explained_variance_ratio = pca(data.values)\n",
    "\n",
    "Comp1 = reducedData[:, 0]\n",
    "Comp2 = reducedData[:, 1]\n",
    "\n",
    "df = pd.DataFrame(reducedData, columns=['Comp1', 'Comp2', 'Comp3', 'Comp4', 'Comp5'])\n",
    "df.insert(0, 'Stock', stocks)\n",
    "frame = df\n",
    "frame.set_index(\"Stock\")\n",
    "\n",
    "plt.scatter(Comp1, Comp2)\n",
    "current_date = datetime.now().date()\n",
    "plt.title('PCA of tech stocks ' + str(current_date))\n",
    "plt.xlabel('Principle Component 1')\n",
    "plt.ylabel('Principle Component 2')\n",
    "\n",
    "for i in range(len(stocks)):\n",
    "    plt.annotate(stocks[i], (Comp1[i], Comp2[i]))\n",
    "    \n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(-1, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36d73d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
